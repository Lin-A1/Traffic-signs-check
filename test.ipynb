{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c19773d-9867-41ea-bd49-9f04b144c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import DatasetFolder, ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038aa215-46f6-4130-9f84-08a3f476d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_dict = {\n",
    "    \"Speed limit (5km)\": 0,\n",
    "    \"Speed limit (15km)\": 1,\n",
    "    \"Speed limit (20km)\": 2,\n",
    "    \"Speed limit (30km)\": 3,\n",
    "    \"Speed limit (40km)\": 4,\n",
    "    \"Speed limit (50km)\": 5,\n",
    "    \"Speed limit (60km)\": 6,\n",
    "    \"Speed limit (70km)\": 7,\n",
    "    \"speed limit (80km)\": 8,\n",
    "    \"speed limit (100km)\": 9,\n",
    "    \"speed limit (120km)\": 10,\n",
    "    \"End of speed limit\": 11,\n",
    "    \"End of speed limit (50km)\": 12,\n",
    "    \"End of speed limit (80km)\": 13,\n",
    "    \"Dont overtake from Left\": 14,\n",
    "    \"No stopping\": 15,\n",
    "    \"No Uturn\": 16,\n",
    "    \"No Car\": 17,\n",
    "    \"No horn\": 18,\n",
    "    \"No entry\": 19,\n",
    "    \"No passage\": 20,\n",
    "    \"Dont Go Right\": 21,\n",
    "    \"Dont Go Left or Right\": 22,\n",
    "    \"Dont Go Left\": 23,\n",
    "    \"Dont Go straight\": 24,\n",
    "    \"Dont Go straight or Right\": 25,\n",
    "    \"Dont Go straight or left\": 26,\n",
    "    \"Go right or straight\": 27,\n",
    "    \"Go left or straight\": 28,\n",
    "    \"Village\": 29,\n",
    "    \"Uturn\": 30,\n",
    "    \"ZigZag Curve\": 31,\n",
    "    \"Bicycles crossing\": 32,\n",
    "    \"Keep Right\": 33,\n",
    "    \"Keep Left\": 34,\n",
    "    \"Roundabout mandatory\": 35,\n",
    "    \"Watch out for cars\": 36,\n",
    "    \"Slow down and give way\": 37,\n",
    "    \"Continuous detours\": 38,\n",
    "    \"Slow walking\": 39,\n",
    "    \"Horn\": 40,\n",
    "    \"Uphill steep slope\": 41,\n",
    "    \"Downhill steep slope\": 42,\n",
    "    \"Under Construction\": 43,\n",
    "    \"Heavy Vehicle Accidents\": 44,\n",
    "    \"Parking inspection\": 45,\n",
    "    \"Stop at intersection\": 46,\n",
    "    \"Train Crossing\": 47,\n",
    "    \"Fences\": 48,\n",
    "    \"Dangerous curve to the right\": 49,\n",
    "    \"Go Right\": 50,\n",
    "    \"Go Left or right\": 51,\n",
    "    \"Dangerous curve to the left\": 52,\n",
    "    \"Go Left\": 53,\n",
    "    \"Go straight\": 54,\n",
    "    \"Go straight or right\": 55,\n",
    "    \"Children crossing\": 56,\n",
    "    \"Care bicycles crossing\": 57,\n",
    "    \"Danger Ahead\": 58,\n",
    "    \"Traffic signals\": 59,\n",
    "    \"Zebra Crossing\": 60,\n",
    "    \"Road Divider\": 61\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c96c6c-eb3e-4446-afb5-094ce17f76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CA_Block(nn.Module):\n",
    "    def __init__(self, channel, h, w, reduction=16):\n",
    "        super(CA_Block, self).__init__()\n",
    " \n",
    "        self.h = h\n",
    "        self.w = w\n",
    " \n",
    "        self.avg_pool_x = nn.AdaptiveAvgPool2d((h, 1))\n",
    "        self.avg_pool_y = nn.AdaptiveAvgPool2d((1, w))\n",
    " \n",
    "        self.conv_1x1 = nn.Conv2d(in_channels=channel, out_channels=channel//reduction, kernel_size=1, stride=1, bias=False)\n",
    " \n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm2d(channel//reduction)\n",
    " \n",
    "        self.F_h = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)\n",
    "        self.F_w = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)\n",
    " \n",
    "        self.sigmoid_h = nn.Sigmoid()\n",
    "        self.sigmoid_w = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    " \n",
    "        x_h = self.avg_pool_x(x).permute(0, 1, 3, 2)\n",
    "        x_w = self.avg_pool_y(x)\n",
    " \n",
    "        x_cat_conv_relu = self.relu(self.conv_1x1(torch.cat((x_h, x_w), 3)))\n",
    " \n",
    "        x_cat_conv_split_h, x_cat_conv_split_w = x_cat_conv_relu.split([self.h, self.w], 3)\n",
    " \n",
    "        s_h = self.sigmoid_h(self.F_h(x_cat_conv_split_h.permute(0, 1, 3, 2)))\n",
    "        s_w = self.sigmoid_w(self.F_w(x_cat_conv_split_w))\n",
    " \n",
    "        out = x * s_h.expand_as(x) * s_w.expand_as(x)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15fba29-66da-4bca-b4f3-d7807fff5674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class ResnetCA(nn.Module):\n",
    "    def __init__(self, model=models.resnet18(pretrained=False)):\n",
    "        super(ResnetCA,self).__init__()\n",
    "        self.resnet = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.ca = CA_Block(channel=512, h=7, w=7)\n",
    "        self.avg_pool = nn.Sequential(*list(model.children())[-2:])[0]\n",
    "        self.fc = nn.Linear(in_features=512, out_features=62, bias=True)\n",
    "    def forward(self, x):\n",
    "        x=self.resnet(x)\n",
    "        # x=x.view(-1,49,512)\n",
    "        x=self.ca(x)\n",
    "        x=x.view(-1,512,7,7)\n",
    "        x=self.avg_pool(x)\n",
    "        x=x.view(x.size(0), -1)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "\n",
    "resnet_ca = ResnetCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a20b389-4d7d-4681-aa10-55a5ba9d42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionTransform:\n",
    "    def __init__(self, model_path, scale=4):\n",
    "        self.sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "        self.sr.readModel(model_path)\n",
    "        self.sr.setModel(\"espcn\", scale)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        upsampled_img_cv = self.sr.upsample(img_cv)\n",
    "        upsampled_img = Image.fromarray(cv2.cvtColor(upsampled_img_cv, cv2.COLOR_BGR2RGB))\n",
    "        return upsampled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620c009c-0889-40d7-81f9-5a30a6eda173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集类\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_files = os.listdir(folder_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.folder_path, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_files[idx]   \n",
    "\n",
    "# 定义预处理变换\n",
    "transform = transforms.Compose([\n",
    "    SuperResolutionTransform(\"ESPCN_x4.pb\"),  # 超分辨率重构\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # 颜色调整\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "    \n",
    "# 加载模型\n",
    "model_path = \"./model/best_model.pth\"\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# 加载数据集\n",
    "test_dataset = ImageDataset(\"./data/test_set/unknow/\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 预测并保存结果到CSV\n",
    "results = []\n",
    "for images, filenames in test_loader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        results.append((filenames[0], predicted.item()))\n",
    "\n",
    "# 将结果保存到CSV\n",
    "df = pd.DataFrame(results, columns=[\"ImageID\", \"label\"])\n",
    "df.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449dc09-2e01-44ca-9bc2-3141e22d52f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
